{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VoxelNet_implementation",
      "provenance": [],
      "authorship_tag": "ABX9TyOED/t3pNmXmE8zfa+jyP2J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gkadusumilli/Voxelnet/blob/master/VoxelNet_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PDrNEWZLNHE",
        "colab_type": "text"
      },
      "source": [
        "#LiDAR point-cloud based 3D object detection implementation withÂ colab\n",
        "\n",
        "Note: Runtime > change runtime > GPU\n",
        "\n",
        "\n",
        "Link to the article explaining crucial topics can be found [here](https://medium.com/@gkadusumilli/lidar-point-cloud-based-3d-object-detection-implementation-with-colab-part-1-of-2-e3999ea8fdd4)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuBBPxRJag2g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/drive/My Drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3t4stiPNi4Z",
        "colab_type": "text"
      },
      "source": [
        "###Clone the VoxelNet repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dk0hG3qBNteJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/gkadusumilli/Voxelnet.git\n",
        "\n",
        "#changing the current working directory\n",
        "%cd /content/drive/My Drive/Voxelnet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qIiMnI0OB0p",
        "colab_type": "text"
      },
      "source": [
        "###Build the necessary files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HubjjpZUN4fu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python setup.py build_ext --inplace"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syeKlurcOSN5",
        "colab_type": "text"
      },
      "source": [
        "###Unzip the dataset folder stored in the drive\n",
        "\n",
        "* Steps to download KITTI dataset, crop and process can be found [here](https://github.com/gkadusumilli/Voxelnet/blob/master/VoxelNet_data_creation.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwqSS4JVORBd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#stored the dataset in AI folder named data_lidar, feel free to rename as you need\n",
        "!unzip \"/content/drive/My Drive/AI/data_lidar.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mqchZdtPAkw",
        "colab_type": "text"
      },
      "source": [
        "###editing config.py python file to change the path directory, if needed (optional step)\n",
        "\n",
        "1. pycat command will be used to view the files \n",
        "\n",
        "**To edit the config.py**\n",
        "1. Copy the python script as displayed with pycat command\n",
        "2. paste in the %%writefile and change the pathdirectory and run the cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgMsxhDOO2Xh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%pycat /content/drive/My Drive/Voxelnet/config.py\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1_r682qPqFL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile ./config.py\n",
        "\n",
        "from easydict import EasyDict as edict\n",
        "\n",
        "__cfg__ = edict()\n",
        "\n",
        "# for dataset dir\n",
        "__cfg__.DATA_DIR = '/content/drive/My Drive/Voxelnet/crop_data'\n",
        "__cfg__.KITTY_EVAL_SCRIPT = \"kitti_eval/launch_test.sh\"\n",
        "__cfg__.CALIB_DIR = ''\n",
        "\n",
        "# selected object\n",
        "__cfg__.DETECT_OBJECT = 'Car'  # Pedestrian/Cyclist\n",
        "__cfg__.NUM_ANCHORS_PER_CELL = 2\n",
        "\n",
        "if __cfg__.DETECT_OBJECT == 'Car':\n",
        "    __cfg__.MAX_POINT_NUMBER = 35\n",
        "    __cfg__.Z_MIN = -3\n",
        "    __cfg__.Z_MAX = 1\n",
        "    __cfg__.Y_MIN = -40\n",
        "    __cfg__.Y_MAX = 40\n",
        "    __cfg__.X_MIN = 0\n",
        "    __cfg__.X_MAX = 70.4\n",
        "    __cfg__.VOXEL_X_SIZE = 0.2\n",
        "    __cfg__.VOXEL_Y_SIZE = 0.2\n",
        "    __cfg__.VOXEL_Z_SIZE = 0.4\n",
        "    __cfg__.VOXEL_POINT_COUNT = 35\n",
        "    __cfg__.INPUT_WIDTH = int((__cfg__.X_MAX - __cfg__.X_MIN) / __cfg__.VOXEL_X_SIZE)\n",
        "    __cfg__.INPUT_HEIGHT = int((__cfg__.Y_MAX - __cfg__.Y_MIN) / __cfg__.VOXEL_Y_SIZE)\n",
        "    __cfg__.INPUT_DEPTH = int((__cfg__.Z_MAX - __cfg__.Z_MIN) / __cfg__.VOXEL_Z_SIZE)\n",
        "    __cfg__.LIDAR_COORD = [0, 40, 3]\n",
        "    __cfg__.FEATURE_RATIO = 2\n",
        "    __cfg__.FEATURE_WIDTH = int(__cfg__.INPUT_WIDTH / __cfg__.FEATURE_RATIO)\n",
        "    __cfg__.FEATURE_HEIGHT = int(__cfg__.INPUT_HEIGHT / __cfg__.FEATURE_RATIO)\n",
        "else:\n",
        "    __cfg__.MAX_POINT_NUMBER = 45\n",
        "    __cfg__.Z_MIN = -3\n",
        "    __cfg__.Z_MAX = 1\n",
        "    __cfg__.Y_MIN = -20\n",
        "    __cfg__.Y_MAX = 20\n",
        "    __cfg__.X_MIN = 0\n",
        "    __cfg__.X_MAX = 48\n",
        "    __cfg__.VOXEL_X_SIZE = 0.2\n",
        "    __cfg__.VOXEL_Y_SIZE = 0.2\n",
        "    __cfg__.VOXEL_POINT_COUNT = 45\n",
        "    __cfg__.INPUT_WIDTH = int((__cfg__.X_MAX - __cfg__.X_MIN) / __cfg__.VOXEL_X_SIZE)\n",
        "    __cfg__.INPUT_HEIGHT = int((__cfg__.Y_MAX - __cfg__.Y_MIN) / __cfg__.VOXEL_Y_SIZE)\n",
        "    __cfg__.INPUT_DEPTH = int((__cfg__.Z_MAX - __cfg__.Z_MIN) / __cfg__.VOXEL_Z_SIZE)\n",
        "    __cfg__.FEATURE_RATIO = 2\n",
        "    __cfg__.LIDAR_COORD = [0, 20, 3]\n",
        "    __cfg__.FEATURE_WIDTH = int(__cfg__.INPUT_WIDTH / __cfg__.FEATURE_RATIO)\n",
        "    __cfg__.FEATURE_HEIGHT = int(__cfg__.INPUT_HEIGHT / __cfg__.FEATURE_RATIO)\n",
        "\n",
        "\n",
        "__cfg__.SCENE_SIZE = [__cfg__.Z_MAX - __cfg__.Z_MIN, __cfg__.Y_MAX- __cfg__.Y_MIN, __cfg__.X_MAX - __cfg__.X_MIN]\n",
        "__cfg__.VOXEL_SIZE = [__cfg__.VOXEL_Z_SIZE, __cfg__.VOXEL_Y_SIZE, __cfg__.VOXEL_X_SIZE]\n",
        "__cfg__.GRID_SIZE = [int(A/B) for A,B in zip(__cfg__.SCENE_SIZE, __cfg__.VOXEL_SIZE)]\n",
        "__cfg__.MAP_SHAPE = [__cfg__.FEATURE_HEIGHT, __cfg__.FEATURE_WIDTH]\n",
        "\n",
        "__cfg__.IMG_WIDTH = 1242\n",
        "__cfg__.IMG_HEIGHT = 375\n",
        "__cfg__.IMG_CHANNEL = 3\n",
        "\n",
        "\n",
        "# set the log image scale factor\n",
        "__cfg__.BV_LOG_FACTOR = 4\n",
        "\n",
        "# For the VFE layer\n",
        "__cfg__.VFE_OUT_DIMS = [32,128]\n",
        "__cfg__.VFE_FINAl_OUT_DIM = 128\n",
        "\n",
        "# cal mean from train set\n",
        "__cfg__.MATRIX_P2 = ([[719.787081,    0.,            608.463003, 44.9538775],\n",
        "                  [0.,            719.787081,    174.545111, 0.1066855],\n",
        "                  [0.,            0.,            1.,         3.0106472e-03],\n",
        "                  [0.,            0.,            0.,         0]])\n",
        "\n",
        "# cal mean from train set\n",
        "__cfg__.MATRIX_T_VELO_2_CAM = ([\n",
        "    [7.49916597e-03, -9.99971248e-01, -8.65110297e-04, -6.71807577e-03],\n",
        "    [1.18652889e-02, 9.54520517e-04, -9.99910318e-01, -7.33152811e-02],\n",
        "    [9.99882833e-01, 7.49141178e-03, 1.18719929e-02, -2.78557062e-01],\n",
        "    [0, 0, 0, 1]\n",
        "])\n",
        "# cal mean from train set\n",
        "__cfg__.MATRIX_R_RECT_0 = ([\n",
        "    [0.99992475, 0.00975976, -0.00734152, 0],\n",
        "    [-0.0097913, 0.99994262, -0.00430371, 0],\n",
        "    [0.00729911, 0.0043753, 0.99996319, 0],\n",
        "    [0, 0, 0, 1]\n",
        "])\n",
        "\n",
        "\n",
        "# Faster-RCNN/SSD Hyper params\n",
        "if __cfg__.DETECT_OBJECT == 'Car':\n",
        "    # car anchor\n",
        "    __cfg__.ANCHOR_L = 3.9\n",
        "    __cfg__.ANCHOR_W = 1.6\n",
        "    __cfg__.ANCHOR_H = 1.56\n",
        "    __cfg__.ANCHOR_Z = -1.0 - __cfg__.ANCHOR_H/2\n",
        "    __cfg__.RPN_POS_IOU = 0.6\n",
        "    __cfg__.RPN_NEG_IOU = 0.45\n",
        "\n",
        "elif __cfg__.DETECT_OBJECT == 'Pedestrian':\n",
        "    # pedestrian anchor\n",
        "    __cfg__.ANCHOR_L = 0.8\n",
        "    __cfg__.ANCHOR_W = 0.6\n",
        "    __cfg__.ANCHOR_H = 1.73\n",
        "    __cfg__.ANCHOR_Z = -0.6 - __cfg__.ANCHOR_H/2\n",
        "    __cfg__.RPN_POS_IOU = 0.5\n",
        "    __cfg__.RPN_NEG_IOU = 0.35\n",
        "\n",
        "if __cfg__.DETECT_OBJECT == 'Cyclist':\n",
        "    # cyclist anchor\n",
        "    __cfg__.ANCHOR_L = 1.76\n",
        "    __cfg__.ANCHOR_W = 0.6\n",
        "    __cfg__.ANCHOR_H = 1.73\n",
        "    __cfg__.ANCHOR_Z = -0.6 - __cfg__.ANCHOR_H/2\n",
        "    __cfg__.RPN_POS_IOU = 0.5\n",
        "    __cfg__.RPN_NEG_IOU = 0.35\n",
        "\n",
        "# for rpn nms\n",
        "__cfg__.RPN_NMS_POST_TOPK = 20\n",
        "__cfg__.RPN_NMS_THRESH = 0.1\n",
        "__cfg__.RPN_SCORE_THRESH = 0.96\n",
        "\n",
        "\n",
        "__cfg__.CORNER2CENTER_AVG = True  # average version or max version\n",
        "\n",
        "\n",
        "cfg = __cfg__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dS-U5a2CQDsR",
        "colab_type": "text"
      },
      "source": [
        "###Training\n",
        "The argument parse details can be found in train.py "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVPQHQ7KQNR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python train.py \\\n",
        "--strategy=\"all\" \\\n",
        "--n_epochs=16 \\\n",
        "--batch_size=2 \\\n",
        "--learning_rate=0.001 \\\n",
        "--small_addon_for_BCE=1e-6 \\\n",
        "--max_gradient_norm=5 \\\n",
        "--alpha_bce=1.5 \\\n",
        "--beta_bce=1 \\\n",
        "--huber_delta=3 \\\n",
        "--dump_vis=\"no\" \\\n",
        "--data_root_dir=\"/content/drive/My Drive/Voxelnet/crop_data\" \\\n",
        "--model_dir=\"model\" \\\n",
        "--model_name=\"model6\" \\\n",
        "--dump_test_interval=3 \\\n",
        "--summary_interval=2 \\\n",
        "--summary_val_interval=40 \\\n",
        "--summary_flush_interval=20 \\\n",
        "--ckpt_max_keep=10 \\"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxaF4MeFQXJV",
        "colab_type": "text"
      },
      "source": [
        "###Visualizing the log files using tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEvkwi4NQfSN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "\n",
        "%tensorboard --logdir summary_logdir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tN3gWqWDQj99",
        "colab_type": "text"
      },
      "source": [
        "###Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F55x-PMuQnaO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python predict.py \\\n",
        "--strategy=\"all\" \\\n",
        "--batch_size=2 \\\n",
        "--dump_vis=\"yes\" \\\n",
        "--data_root_dir=\"../DATA_DIR/T_DATA/\" \\\n",
        "--dataset_to_test=\"validation\" \\\n",
        "--model_dir=\"model\" \\\n",
        "--model_name=\"model6\" \\\n",
        "--ckpt_name=\"\" \\"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}